---
title: "Modelos de marketing mix: datos agregados"
output: html_notebook
bibliography: 
 - "../referencias/referencias.bib"
 - "../referencias/paquetes.bib"
---


En este ejemplo veremos una introducción a la construcción, evaluación y
uso de modelos de marketing mix, que se usan ocasionalmente para evaluar
la efectividad del marketing mix, en particular gasto de publicidad a lo largo
de varios canales (TV, búsqueda, display, espectaculares, etc.).

```{r}
library(cmdstanr)
library(posterior)
library(tidyverse)
library(patchwork)
source("../R/simular_resumenes.R")
```

### Problema

Cuando una empresa asigna recursos para hacer publicidad, 
muchas veces no existen medidas directas de que tan efectiva fue esa publicidad. 
Los modelos de marketing mix intentan atribuir efectos observados en las ventas
a distintos canales de publicidad, de manera que podamos asignar cantidades monetarias
(o unidades vendidas, conversiones, etc.) a al inversión en distintos canales.

En su version más simple, tenemos varias entradas del marketing mix: gasto en distintos
canales de publicidad, promociones, medidas de distribución, precios (que puede
ser para una marca o una unidad SKU, o pueden ser para varias marcas incluyendo competidores),
y una salida que mide el desempeño del mix, como pueden ser las ventas. Estos datos
generalmente están disponibles a nivel semanal durante algunos años.

Finalmente, quisiéramos hacer uso de estos modelos para diseñar planes de inversión
que sean eficientes, y con alto retorno sobre inversión.

En este caso vemos unos datos relativamente simples de ventas de queso
a lo largo de varias tiendas. Los datos son de @rossi2012 y se pueden encontrar
en el paquete @bayesm.
 

### Análisis conceptual

En este caso queremos evaluar cuál es el efecto de poner productos en
*displays* o exhibidores especiales en tiendas, lo cual tiene un costo. Tenemos los siguientes datos

- Ventas por semana por agregado de tiendas (por ejemplo, tiendas Lucky en Los Angeles)
- Precio de promedio de venta en cada semana por agregado de tiendas
- % del total de volumen que estuvo en exhibición (a lo largo de la semana y de todas
las tiendas particulares que constituyen cada agregado)

- Las series de tiempo de ventas para cada tienda están influidas por varios
efectos para los que tenemos covariables. 

- Supondremos que precio y exhibición tienen un
efecto en la semana donde están presentes, y supondremos que no interactúan. 

- El efecto del precio lo consideraremos multiplicativo, como es usual en
este tipo de problemas: por ejemplo, un incremento del
5% tienen un efecto de -5%/2 = -2.5% en ventas.

- ¿Cómo debe ser el efecto de producto en exhibición? Supongamos que el número
de unidades de venta esperadas sin exhibición en una tienda y semana dadas 
es igual a $N(i,t)$, y que cuando todas las unidades están en exhibición
son $N(i, t)(1+ \beta)$. El indicador $\beta$ mide cuánto se incrementan las
unidades vendidas cuando están todas en exhibición, y es el máximo
efecto que puede tener la exhibición. Supondremos que cuando
una proporción $p$ de las unidades están en exhibición, esperamos
observar ventas de $N(i, t)(1 + \beta p)$.

Supondremos en primer lugar que $beta$ es constante a lo largo de las tiendas.




### Espacio de observaciones

No todas las tiendas registran el mismo número de semanas de ventas. Así que
podemos usar índices, por ejemplo:

- $$y_{[\mathrm{indice}(i, t)]}$$ son las ventas observadas de la tienda $i$ en 
la semana $t$.

Usamos una notación simplar para $disp$, la proporción del volumen de la tienda
que está en exhibición y $precio$, el precio.

```{bash}
sed -n '/^data/,/\}/p' ../stan/modelo.stan
```

### Estadísticas resumen

- Elasticidad precio por tienda.
- Valor alcanzado de incremental en valor debido a las exhibiciones, por tienda y a total.
- Curvas de incremento % en ventas (unidades y valor) dependiendo del % de volumen en exhibición. Por tienda y a total.


### Desarrollo del modelo

Como nos interesa trabajar con elasticidades precio, modelaremos el logaritmo
de las ventas unitarias en términos del logaritmo de precio:

$$\log(y_{i,t}) = \alpha_{i} + \beta_{i}\log \left(\frac{\mathrm{precio}}{\mathrm{precio_{prom}}}\right ) + \gamma_i \mathrm{disp}_{i,t} +   \epsilon_{i,t}$$
donde $\epsilon$ mide variables no medidas. La razón de utilizar la variable
de exhibiciones sin logartimo es que de esta forma el efecto de exhibiciones 
es de la forma
$$\frac{\delta y}{y} \approx \gamma \Delta\textrm{disp}$$
y en cuanto al precio,
$$\frac{\delta y}{y} \approx \beta \frac{\Delta p}{p}$$

- Suponemos ventas base constante (no hay crecimiento de ventas no debido a otras variables,
por ejemplo). Este es un supuesto que habrá que checar.
- Supongemos que los errores $\epsilon$ son iid, lo cual también habrá que checar.
- Para interpretar causalmente estos efectos y poder usar este modelo
para diseñar estrategias, es necesario suponer que
no existen otras covariables no incluídas en el modelo
que afectan a ventas y precio o ventas y exhibiciones
directamente. Esto puede pasar en muchos casos, por ejemplo, en épocas particulares
del año(navidad: hay más ventas y más artículos con promoción, etc)

Ahora tenemos que poner modelos para estas cantidades desconocidas. En primer lugar,
usaremos el precio promedio, de forma que $\alpha$ se interpreta como el nivel
esperado de ventas a precio promedio y sin exhibición. Tenemos que saber algo
acerca de los niveles de venta generales de la tienda, pero podríamos comenzar con
(son tiendas relativamente chicas), para las ventas semanales.

Podemos investigar qué niveles generales de ventas tienen las ventas. Quizá nos
informa que usualmente están entre 200 y 5000 unidades a la semana.
Así que podríamos poner (tomando logaritmo de la media, y calculando )

$$\alpha_i \sim N(8, 1.5)$$
En la media obtenemos unas 3000 unidades (exponencial de 8)


Suponemos que la elasticidad precio es similar a lo largo de las tiendas, pero puede
variar. Usarmos:

$$\beta_i \sim N(\beta_0, \sigma_\beta)$$
y como iniciales, ponemos $\beta_0 ~ N(-1.5, 0.5)$, es decir, esperamos una elasticidad
precio media entre -2.5 y -0.5. Ponemos $\sigma_\beta \sim N^+(0, 0.25)$, lo que implica
que consideramos que las elasticidades precio pueden ser muy similares, pero también
puede haber variabilidad hasta de $+/-0.5$ de tienda a tienda.

Ahora continuamos con $\gamma_i$. Pondremos
$$\gamma_i \sim N(\gamma_0, \sigma_\gamma)$$
Recordamos que $e^\gamma_i$ será el efecto multiplicativo más grande (en incremento porcentual) que
pueden tener las exhibiciones (si todo el volumen está en exhibición). Ponemos
$$\gamma_0 ~\sim N^+(0, 0.2)$$
(más o menos un incremento máximo de 40% en promedio), y
$$\sigma_\gamma \sim  ~ N^+(0, 0.05)$$.

Finalmente, pondremos $\epsilon ~ N(0, \sigma)$, con 

$$\sigma \sim N^+(0, 0.15),$$ 
que
es variación considerable:

```{r}
abs(rnorm(2000,0,0.25)) %>% quantile() %>% round(3)
```

$\sigma=1$ corresponde a un error en logaritmo de +/-2 unidades, que es variación
de 1/7 - 7 veces alrededor del valor esperado.


Verificaremos simulando el ensemble bayesiano y calculando nuestras medidas resumen.

### Simular ensamble bayesiano

Usaremos los datos de tiendas, precios y exhibición observadas (no las ventas)
para simular ventas.

```{r}
datos <- read_csv("../datos/cheese.csv") %>% 
  rename(tienda = RETAILER, venta_unidades = VOLUME, disp = DISP, precio = PRICE) %>% 
  mutate(indice = row_number()) %>% 
  group_by(tienda) %>% 
  arrange(tienda, indice) %>% 
  mutate(semana_id = row_number()) %>% 
  ungroup() %>% 
  mutate(tienda_id = as.numeric(as.factor(tienda))) %>% 
  mutate(indice = row_number() %>% as.integer())
lista_dat <- list("N" = nrow(datos), "m" = max(datos$tienda_id),
                  "tienda_id"=datos$tienda_id, "semana_id"=datos$semana_id,
                  "precio" = datos$precio, "acv_disp"=datos$disp)
                  
jsonlite::write_json(lista_dat, "../datos/datos_prueba.json")


sim_datos <- jsonlite::read_json("../datos/datos_prueba.json", simplifyVector = TRUE)
parametros <- jsonlite::read_json("../datos/datos_inicial.json", simplifyVector = TRUE)
print(parametros)
```


```{r, message=FALSE, include=FALSE}
sim_ensemble_datos <- c(sim_datos, parametros)
ruta <- file.path("../stan/simular_ensemble_modelo.stan")
modelo_inicial <- cmdstan_model(ruta)
ensemble <- simular_ensemble(modelo_inicial, sim_ensemble_datos, 100)
```

Ahora podemos ver algunas simulaciones. En primer lugar, vemos cómo se 
ven las ventas en el tiempo:





```{r}
num_sim <- 17
y_sim <- ensemble$draws("y")[num_sim,1,] %>% as.numeric
datos_sim <- datos %>% select(-venta_unidades)
datos_sim$venta_unidades <- y_sim
ggplot(datos_sim, aes(x = semana_id, y = venta_unidades, group = tienda_id)) +
  geom_line() 
```
Algunas simulaciones son extremas (para una tienda). Si vemos algunas tiendas al azar::

```{r}
set.seed(834)
ggplot(datos_sim %>% filter(tienda_id %in% sample(1:88, 12)), 
       aes(x = semana_id, y = venta_unidades, group = tienda_id)) +
  geom_line() + facet_wrap(~ tienda_id, scales = "free_y")
```
Observamos variación considerable, aunque quizá con valores muy altos. Como son
series de tiempo, estas replicaciones parecen ser muy poco suaves - quizá es necesario
construir correlaciones entre los resiudales. Por el
momento, estas simulaciones las aceptamos como factibles, e incluye a tiendas
chicas y grandes.

Ventas promedio y máximos:

```{r}
datos_sim %>% group_by(tienda, tienda_id) %>% 
  summarise(media_ventas = mean(venta_unidades) %>% as.integer, 
            maximo=max(venta_unidades) %>% as.integer)
```

Las elasticidades son razonables, aunque quizá deberíamos considerar más variación 
de tienda a tienda:

```{r}
elasticidad_tbl <- resumir_precio(ensemble, sim_ensemble_datos) 
elasticidad_tbl %>% filter(n_sim==num_sim) %>% pull(beta) %>% quantile
```

```{r}
ensemble$draws("gamma") %>% as_draws_df %>% 
  as_tibble %>% filter(.draw == num_sim) %>% 
  as.numeric %>% quantile()
```



```{r}
retorno_base_tbl <- contribucion_disp(ensemble, sim_ensemble_datos) %>% 
  pivot_wider(names_from = variable, values_from = valor)
retorno <- retorno_base_tbl %>% filter(n_sim == num_sim)
```


```{r}
ggplot(retorno, aes(x = disp_media, y = retorno_disp_pct, colour = gamma)) + 
  geom_point() 
```

Descomposición

```{r}

```


### Ajustar al ensemble simulado

Ahora veremos si podemos ajustar el modelo al ensemble simulado

```{r}
num_iter <- 17
ventas_sim <- ensemble$draws("y") %>% as_draws_df() %>% 
  as_tibble() %>% 
  filter(.draw == num_iter)  %>% 
  select(-.iteration, -.chain, -.draw) %>% as.numeric()
```


```{r}
ruta <- file.path("../stan/modelo.stan")
modelo <- cmdstan_model(ruta)
```


```{r}
datos_1 <- c(sim_ensemble_datos, list("y" = ventas_sim %>% as.numeric))
ajuste <- modelo$sample(data = datos_1,
                          seed = 2210,
                          iter_sampling = 500, iter_warmup = 500,
                          refresh = 100, parallel_chains = 4,
                          show_messages = FALSE)
ajuste
```

```{r}
ajuste$cmdstan_diagnose()
```

Este ajuste no tuvo problemas. Examinemos las elasticidades

```{r}
ajuste$summary("beta") 
```


```{r}
elasticidad <- ajuste$summary("beta") %>% select(variable, mean) %>% 
  rename(media_beta = mean)
gamma_disp <- ajuste$summary("gamma") %>% select(mean) %>% 
  rename(media_gamma = mean)
bind_cols(elasticidad, gamma_disp) %>% 
  ggplot(aes(x=media_beta, y = media_gamma)) + geom_point()
```
Vemos que en general los displays parecen tener un efecto considerable. Algunas
estimaciones de la elasticidad son positivas, lo que probablemente indica un 
defecto en el modelo (variables adicionales o información inicial)

```{r}
ajuste$summary(c("sigma_beta", "sigma_gamma", "sigma"))
```


### Calibración inferencial

### Ajuste a las observaciones

Los datos son los siguientes:

```{r}
datos_ventas <- c(sim_ensemble_datos, list("y" = datos$venta_unidades))
ajuste <- modelo$sample(data = datos_ventas,
                          seed = 2210,
                          iter_sampling = 500, iter_warmup = 500,
                          refresh = 100, parallel_chains = 4,
                          show_messages = FALSE)
ajuste
```
```{r}
ajuste$cmdstan_diagnose()
```

El modelo corrió sin problemas numéricos

```{r}
ajuste$summary(c("beta")) %>% pull(mean) %>% qplot()
```

```{r}
ajuste$summary(c("gamma")) %>% pull(mean) %>% qplot()
```



### Verificación posterior dentro de muestra

### Siguientes pasos

### Conclusiones

